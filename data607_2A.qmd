---
title: "2A SQL & R Deliverable"
author: "Desiree Thomas"
format: html
editor: visual
---

## Approach

Data is a highly value asset and used by virtually all companies. This data is often used by streaming services such as Netflix, Youtube, HBO Max, Paramount+, and many more. Compare your experiences with these streaming services vs. your experience with cable TV. I am going to develop my business approach/question further: https://arxiv.org/pdf/1609.02451.

We are being asked to create the dataset that will later be used for a recommender system. I chose these 6 recent popular movies: 'Deadpool & Wolverine'(2024), 'Dune: Part 2' (2024), 'Barbie' (2023), 'Oppenheimer' (2023), 'Spider-Man: Across the Spider-Verse (2023). The process and strategy used in this first part of the assignment will hopefully lead to the college program I work for being better able to randomly anticipate what the students may wish to watch or which movies to suggest when sending out forms for students to select what they would like to watch from a list of movies. This encourages them to show up for events, shows student participation, helps maintain student- staff connection and hopefully improves their connection to the campus, which students often self-report as 'low' (often observed at commuter campuses).

For this assignment, I chose to generate synthetic data. This data will consist of approximately 80 'students' and their ratings. It is important to note that because this is synthetic data, I was careful to have Gemini (or any other LLM) generate data that included blanks. Not all students are likely to have seen all films, though I did have the data account for film students who tend to be movie buffs. There are some 'staff' data sprinkled in to add potential range in 'age' and background. Synthetic data was also used to "buff up" the numbers of 'users' for the future recommender system. Due to this being a portfolio level assignment, I have also added 'Account IDs' since streaming services use similar items to track and personalization their services to both individuals and accounts. Geographic data and ages would be interesting to add as well but I think I will stick with the basics and gain comfort working with both a new programming language and software.

The data will be stored as a CSV and then transferred to PostGres. I anticipate that loading the data and turning the blanks into NULLS will present a challenge for me due to my limited knowledge of both R and SQL. I will also have to take care with formatting. With some research i have realized that SQL is normally used with Normalization but R needs a single dataframe (Denormalized) or even a matrix format. I will have to work through making JOIN queries in SQL before I can pull it into R.

As I work through this project, I know that my approach will need to change. The outline I have set above is not final and is subject to change.

## Package Install

Install these packages if you do not already have them: "DBI", "RPostgres", "tidyverse", "rstudioapi"

## Load Packages

```{r}
library(DBI)
library(RPostgres)
library(tidyverse)
library(rstudioapi)
```

#Set up Postgres connection:

```{r}
con <- dbConnect(RPostgres::Postgres(),
                 dbname = "movie_ratings",
                 host = "localhost", 
                 port = 5432,
                 user = "postgres",
                 password = rstudioapi::askForPassword("Database Password"))

```
#Getting the Data
```{r}



SQL_query <- "
  SELECT  p.profile_name, m.title,r.rating
  FROM ratings r
  LEFT JOIN profiles p ON r.profile_id = p.profile_id
  LEFT JOIN movies m ON r.movie_id = m.movie_id;
"
df <- dbGetQuery(con, SQL_query)

print(head(df))




```
#Analyzing the data 
```{r}
#Homework Analysis chunk


movie_watchers_analysis <- df %>% group_by(profile_name) %>% 
  summarise(
    movies_rated = sum(!is.na(rating)), 
    total_watched = n()
) %>% 
  arrange(desc(movies_rated))
print("Ranking The Users")
print(movie_watchers_analysis)

movie_stats <- df %>% 
  group_by(title)%>%
  summarise(
    average_score = mean(rating, na.rm = TRUE), 
    count = sum(!is.na(rating))
  ) %>% 
  arrange(desc(average_score))
print("Ranking The Movies")
print(movie_stats)


#Count the average ratings per user and movie AND computer average ratings

#Users 
count_users <- df %>% 
  group_by(profile_name)%>%
  summarise(
    movies_rated = sum(!is.na(rating))
  ) %>% 
  arrange(desc(movies_rated))

print("Ratings Per User")
print(count_users)
  

#Movies

```







#LLM Prompt

User: I need you to set up the PostGres connection.

LLM: Copy this into your script. This loads your tools and opens the secure tunnel to Postgres.

Why this matters: rstudioapi keeps your password out of the code. This is the "Portfolio Standard."

R 1. SETUP library(DBI) library(RPostgres) library(tidyverse) library(rstudioapi)

2.  CONNECT When you run this, look for the popup box to type your password. con \<- dbConnect(RPostgres::Postgres(), dbname = "movie_ratings", host = "localhost", port = 5432, user = "postgres", password = rstudioapi::askForPassword("Database Password")) Run Block 1. (Ctrl+Enter).

Checkpoint: Did the popup appear? Did it run without error?

LLM's explanation of code: Think of RStudio and Postgres as two separate buildings. Right now, the doors are locked. We need to build a secure tunnel between them.

We use the DBI library (Database Interface) as the blueprint for the tunnel, and RPostgres as the specific materials for a Postgres tunnel.

The Syntax: To open the tunnel, we use a function called dbConnect(). It needs 5 pieces of ID:

Driver: What kind of database is it? (RPostgres::Postgres())

DB Name: dbname

Host: Where is it? (Usually localhost)

User: Who are you? (postgres)

Password: The key.

Your Challenge: I want you to write the connection code.

Security Tip: Instead of typing your password in quotes (which is unsafe), use this function: rstudioapi::askForPassword("Enter Password"). This forces R to pop up a secure window.

Try writing the con <- dbConnect(...) block in your script. Paste what you have here so I can check it.

#LLM Citation
Google DeepMind. (2025). Gemini 3 Pro. [Large Language model]. 
https://gemini.google.com. Acessed February 7, 2026. 
